{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Helps Learning\n",
    "\n",
    "Very simply: If your data has structure, build your model in such a way that your network doesn't have to learn those relationships implicitly.\n",
    "\n",
    "For example, if you know that color doesn't matter for identifying a shape in an image, it would benefit your model to use grayscale from the beginning, rather than having your model learn the RGB values away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Invariance\n",
    "\n",
    "Another issue is learning about the same object in different parts of the image. A kitten in the left corner, and a kitten in the right corner, are both just kittens. We should not have to learn both of these independently. \n",
    "\n",
    "This is called translation invariance.\n",
    "\n",
    "### Weight Sharing\n",
    "The solution to these problems is called Weight Sharing, where you train weights in parallel. This can be done many different ways, from Convolutional Neural Networks for images, to Recurrent Neural Networks for text."
   ]
  },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnets\n",
    "\n",
    "Let's take an image, and build a small neural network to fit it. Then, scan the image while outputing to a new \"image\", but instead of RGB depth, it has n-depth, where n is the number of scans done over the image.\n",
    "\n",
    "If you scan once, it's simply a 2-layer matrix multiply. But if you scan multiple times, that's a convolution. The idea is that we are going from stacks of matrix multiplies, to stacks of convolutions.\n",
    "\n",
    "![image1.png](Images/Lesson3/image1.png)\n",
    "\n",
    "![Image2.png](Images/Lesson3/Image2.png)\n",
    "\n",
    "![Image3.png](Images/Lesson3/Image3.png)\n",
    "\n",
    "![Image4.png](Images/Lesson3/Image4.png)\n",
    "\n",
    "![Image5.png](Images/Lesson3/Image5.png)\n",
    "\n",
    "![Image6.png](Images/Lesson3/Image6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Covnets\n",
    "\n",
    "* Pooling\n",
    "* 1x1 Convolutions\n",
    "* Inception Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "\n",
    "Simple striding is a very aggressive way to scan an image. Lots of information is lost, and many \"hard\" assumptions are made. What if, instead, we took the convolution of not just the stride, but also the area around the stride? This is called pooling. There are few ways to go about it.\n",
    "\n",
    "#### Max Pooling\n",
    "One idea is to take a response point, and then compute the max of it and all the surrounding responses. \n",
    "\n",
    "* Parameter free!\n",
    "* Often more accurate\n",
    "* More expensive\n",
    "* More hyper parameters (pooling size, pooling stride)\n",
    "\n",
    "A typical setup of for this is:\n",
    "\n",
    "1. Classifier\n",
    "2. Fully Connected\n",
    "3. Fully Connected\n",
    "4. Max Pooling\n",
    "5. Convolution\n",
    "6. Max Pooling\n",
    "7. Convolution\n",
    "8. Image\n",
    "\n",
    "#### Average Poolng\n",
    "Instead of computing MAX(Xi), we compute MEAN(Xi). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1x1 Convolutions\n",
    "\n",
    "Instead of a patch, lets look at just a pixel. Why? If you intersparse convolutions with 1x1 convolutions, you get mini-neural networks for your convolutions! This makes your model deeper, and have more parameters, without completely changing your structure. This is because they aren't really convolutions, just matrix multiplies."
   ]
  },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Module\n",
    "\n",
    "At every layer, we must make a choice between a convolution, pooling, 1x1 convolution, a NN layer, etc. But why choose? Just use them all! This is called an inception module.\n",
    "\n",
    "![Image7.png](Images/Lesson3/Image7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
